{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"train_labeled.h5\" (mode r)>)\n",
      "KeysView(<HDF5 file \"train_unlabeled.h5\" (mode r)>)\n",
      "KeysView(<HDF5 file \"test.h5\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "f_train_l = h5py.File('train_labeled.h5','r')\n",
    "f_train_ul = h5py.File('train_unlabeled.h5','r')\n",
    "f_test = h5py.File('test.h5','r')\n",
    "print(f_train_l.keys())\n",
    "print(f_train_ul.keys())\n",
    "print(f_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 group \"/train\" (6 members)>)\n",
      "KeysView(<HDF5 group \"/train\" (4 members)>)\n",
      "KeysView(<HDF5 group \"/test\" (4 members)>)\n"
     ]
    }
   ],
   "source": [
    "a_train_l = f_train_l['train']\n",
    "a_train_ul = f_train_ul['train']\n",
    "a_test = f_test['test']\n",
    "print(a_train_l.keys())\n",
    "print(a_train_ul.keys())\n",
    "print(a_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a_train_ul['block0_values']\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# axis0 -> Labels [shape (129,)]\n",
    "# axis1 -> id column [shape (9000,)] [shape (21000,)]\n",
    "# block0_items -> traits labels [shape (128,)]\n",
    "# block0_values -> traits values [shape (9000,128)] [shape (21000,128)]\n",
    "# block1_items -> 'y' label\n",
    "# block1_values -> y column (without label) [shape (9000,1)] [shape (21000,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_l = a_train_l['block0_values'][()]\n",
    "X_train_l = np.float32(X_train_l)\n",
    "y_train_l = a_train_l['block1_values'][()]\n",
    "y_train_l = np.float32(y_train_l)\n",
    "X_train_ul = a_train_ul['block0_values'][()]\n",
    "X_train_ul = np.float32(X_train_ul)\n",
    "y_train_l = y_train_l[:,0]\n",
    "X_test = a_test['block0_values'][()]\n",
    "X_test = np.float32(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total = X_train_l.tolist()+X_train_ul.tolist()\n",
    "X_total = np.asarray(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Are there zero columns?\n",
    "def is_zero_vector(x):\n",
    "    count = 0\n",
    "    for i in arange(len(x)):\n",
    "        if x[i] == 0.:\n",
    "            count += 1\n",
    "    if count == len(x):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_i = list([])\n",
    "for k in arange(len(X_total[0,:])):   \n",
    "    if is_zero_vector(X_total[:,k]):\n",
    "        zero_i.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 28, 31, 41, 54, 61, 64, 80, 92, 93, 99, 125]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_l = delete(X_train_l, zero_i, 1)\n",
    "X_train_ul = delete(X_train_ul, zero_i, 1)\n",
    "X_test = delete(X_test, zero_i, 1)\n",
    "X_val = X_train_l[:,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Shuffle\n",
    "\"\"\" Added the 'list' thing here because of python 3\"\"\"\n",
    "c = list(zip(y_train_l, X_train_l))\n",
    "random.shuffle(c)\n",
    "random.shuffle(X_train_ul)\n",
    "y_train_l, X_train_l = zip(*c)\n",
    "y_train_l = asarray(y_train_l)\n",
    "X_train_l = asarray(X_train_l)\n",
    "\n",
    "X_train_l, X_val = X_train_l[:-500], X_train_l[-500:]\n",
    "y_train_l, y_val = y_train_l[:-500], y_train_l[-500:]\n",
    "ids = a_test['axis1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "X_val -= np.mean(X_train_l, axis = 0)\n",
    "X_test -= np.mean(X_train_l, axis = 0)\n",
    "X_train_ul -= np.mean(X_train_l, axis = 0)\n",
    "X_train_l -= np.mean(X_train_l, axis = 0)\n",
    "\n",
    "\n",
    "temp = np.std(X_train_l, axis = 0)\n",
    "for i in range(len(temp)):\n",
    "    if temp[i]==0.: #or math.isnan(temp[i]):\n",
    "        temp[i]=1\n",
    "\n",
    "X_val /= temp\n",
    "X_test /= temp\n",
    "X_train_l /= temp\n",
    "X_train_ul /= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 116)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMM(covariance_type='diag', init_params='wmc', min_covar=0.001,\n",
       "  n_components=10, n_init=40, n_iter=100, params='wmc', random_state=None,\n",
       "  thresh=None, tol=0.001, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total = X_train_l.tolist()+X_train_ul.tolist()\n",
    "X_total = np.asarray(X_total)\n",
    "\n",
    "g = mixture.GMM(n_components=10,n_iter=100,n_init=40)\n",
    "g.fit(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PRED_val=g.predict(X_val)\n",
    "TRUE_val = np.asarray([int(item) for item in y_val])\n",
    "\n",
    "def get_accuracy(PRED_val):\n",
    "    no_correct=0\n",
    "    for i in range(len(PRED_val)):\n",
    "        if PRED_val[i]==TRUE_val[i]:\n",
    "            no_correct+=1\n",
    "    accuracy=no_correct/shape(y_val)[0]\n",
    "    return accuracy\n",
    "\n",
    "def valid(i1,i2,i3,i4,i5,i6,i7,i8,i9,i10):\n",
    "    permutation=[i1,i2,i3,i4,i5,i6,i7,i8,i9,i10]\n",
    "    validity=1\n",
    "    for i in range(len(permutation)):\n",
    "        for j in range(len(permutation)):\n",
    "            if i!=j and permutation[i]==permutation[j]:\n",
    "                validity=0\n",
    "    return validity\n",
    "\n",
    "def maximize_accuracy(PRED_val):\n",
    "    best_acc=0\n",
    "    best_acc_perm=[0,1,2,3,4,5,6,7,8,9]\n",
    "    nextone=0\n",
    "    for i in itertools.permutations([0,1,2,3,4,5,6,7,8,9]):\n",
    "        permutation=list(i)\n",
    "        if permutation[0]==nextone:\n",
    "            nextone+=1\n",
    "            print(nextone,\"of 10\")\n",
    "        temp_pred=permute_labels(PRED_val,permutation)\n",
    "        acc=get_accuracy(temp_pred)\n",
    "        if acc>best_acc:\n",
    "            best_acc=acc\n",
    "            best_acc_perm=permutation\n",
    "            print(permutation)\n",
    "            print(best_acc, \"accuracy\")\n",
    "    return best_acc, best_acc_perm\n",
    "\n",
    "def exchange_labels(PRED_val,i,j):\n",
    "    \"\"\" Changes all labels i to j and vica versa \"\"\"\n",
    "    for k in range(len(PRED_val)):\n",
    "        if PRED_val[k]==i:\n",
    "            PRED_val[k]=11\n",
    "    for k in range(len(PRED_val)):\n",
    "        if PRED_val[k]==j:\n",
    "            PRED_val[k]=i\n",
    "    for k in range(len(PRED_val)):\n",
    "        if PRED_val[k]==11:\n",
    "            PRED_val[k]=j\n",
    "    return PRED_val\n",
    "\n",
    "def permute_labels(PRED_val,permutation):\n",
    "    \"\"\" Permutes labels consistently according to permutation vector \"\"\"\n",
    "    # First assign temporary labels, shifted by 10\n",
    "    for k in range(len(PRED_val)):\n",
    "        PRED_val[k]+=10\n",
    "        \n",
    "    # Next we check the i-th component in permuation (e.g. 1) and change all 10+i-s (11) to their new value (e.g. 7)\n",
    "    for i in range(len(permutation)):\n",
    "        for k in range(len(PRED_val)):\n",
    "            if PRED_val[k]==i+10:\n",
    "                PRED_val[k]=permutation[i]\n",
    "    # Done!\n",
    "    return PRED_val\n",
    "\n",
    "#print(100*accuracy,\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "0.078 accuracy\n",
      "[0, 1, 2, 3, 4, 5, 6, 8, 7, 9]\n",
      "0.088 accuracy\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 8, 7]\n",
      "0.102 accuracy\n",
      "[0, 1, 2, 3, 4, 6, 8, 5, 7, 9]\n",
      "0.13 accuracy\n",
      "[0, 1, 2, 3, 4, 6, 9, 5, 8, 7]\n",
      "0.142 accuracy\n",
      "[0, 1, 2, 3, 6, 4, 9, 8, 7, 5]\n",
      "0.15 accuracy\n",
      "[0, 1, 2, 4, 3, 9, 8, 5, 6, 7]\n",
      "0.156 accuracy\n",
      "[0, 1, 2, 4, 5, 3, 7, 6, 9, 8]\n",
      "0.162 accuracy\n",
      "[0, 1, 2, 4, 5, 7, 3, 9, 8, 6]\n",
      "0.188 accuracy\n",
      "[0, 1, 2, 4, 8, 7, 3, 9, 6, 5]\n",
      "0.192 accuracy\n",
      "[0, 1, 2, 5, 8, 4, 3, 7, 9, 6]\n",
      "0.206 accuracy\n",
      "[0, 1, 3, 4, 2, 6, 5, 9, 7, 8]\n",
      "0.214 accuracy\n",
      "[0, 1, 3, 6, 4, 2, 9, 8, 7, 5]\n",
      "0.216 accuracy\n",
      "[0, 1, 4, 5, 3, 6, 8, 2, 9, 7]\n",
      "0.23 accuracy\n",
      "[0, 2, 3, 1, 5, 8, 4, 9, 6, 7]\n",
      "0.25 accuracy\n",
      "[0, 2, 3, 4, 5, 7, 6, 1, 8, 9]\n",
      "0.256 accuracy\n",
      "[0, 2, 3, 4, 6, 7, 5, 8, 9, 1]\n",
      "0.282 accuracy\n",
      "[0, 2, 3, 4, 7, 8, 9, 6, 5, 1]\n",
      "0.322 accuracy\n",
      "[0, 2, 4, 1, 6, 8, 3, 7, 9, 5]\n",
      "0.33 accuracy\n",
      "[0, 2, 7, 9, 1, 8, 4, 6, 3, 5]\n",
      "0.336 accuracy\n",
      "[0, 2, 9, 5, 7, 4, 8, 3, 1, 6]\n",
      "0.364 accuracy\n",
      "[0, 6, 3, 5, 4, 1, 8, 2, 7, 9]\n",
      "0.374 accuracy\n",
      "2 of 10\n",
      "[1, 2, 3, 4, 7, 0, 5, 6, 9, 8]\n",
      "0.398 accuracy\n",
      "[1, 2, 3, 5, 8, 6, 7, 0, 9, 4]\n",
      "0.4 accuracy\n",
      "[1, 3, 8, 2, 7, 0, 6, 5, 4, 9]\n",
      "0.414 accuracy\n",
      "[1, 4, 5, 2, 7, 9, 8, 3, 0, 6]\n",
      "0.426 accuracy\n",
      "[1, 7, 3, 4, 6, 9, 0, 2, 5, 8]\n",
      "0.432 accuracy\n",
      "3 of 10\n",
      "[2, 6, 8, 4, 1, 5, 7, 3, 0, 9]\n",
      "0.446 accuracy\n",
      "[2, 8, 4, 9, 3, 1, 6, 7, 5, 0]\n",
      "0.458 accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-21993f0ac34e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_acc_perm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaximize_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-14a4cdce86fa>\u001b[0m in \u001b[0;36mmaximize_accuracy\u001b[1;34m(PRED_val)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mnextone\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"of 10\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtemp_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpermute_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-14a4cdce86fa>\u001b[0m in \u001b[0;36mpermute_labels\u001b[1;34m(PRED_val, permutation)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mPRED_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[0mPRED_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# Done!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc, best_acc_perm = maximize_accuracy(PRED_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "g.predict(X_test)\n",
    "\"\"\" Still need to permute this according to the best permutation!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamas/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X_train_l, y_train_l)\n",
    "PRED_val=g.predict(X_val)\n",
    "TRUE_val = np.asarray([int(item) for item in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "0.05 accuracy\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 8]\n",
      "0.056 accuracy\n",
      "[0, 1, 2, 3, 4, 5, 7, 6, 8, 9]\n",
      "0.108 accuracy\n",
      "[0, 1, 2, 4, 3, 5, 6, 7, 8, 9]\n",
      "0.172 accuracy\n",
      "[0, 1, 3, 2, 5, 7, 6, 8, 4, 9]\n",
      "0.174 accuracy\n",
      "[0, 2, 3, 1, 4, 7, 5, 8, 9, 6]\n",
      "0.186 accuracy\n",
      "[0, 2, 3, 1, 5, 7, 9, 4, 6, 8]\n",
      "0.198 accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-21993f0ac34e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_acc_perm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaximize_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-14a4cdce86fa>\u001b[0m in \u001b[0;36mmaximize_accuracy\u001b[1;34m(PRED_val)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mnextone\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"of 10\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtemp_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpermute_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-14a4cdce86fa>\u001b[0m in \u001b[0;36mpermute_labels\u001b[1;34m(PRED_val, permutation)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRED_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mPRED_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[0mPRED_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# Done!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc, best_acc_perm = maximize_accuracy(PRED_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "X_val -= np.mean(X_train_l, axis = 0)\n",
    "X_test -= np.mean(X_train_l, axis = 0)\n",
    "X_train_ul -= np.mean(X_train_l, axis = 0)\n",
    "X_train_l -= np.mean(X_train_l, axis = 0)\n",
    "\n",
    "\n",
    "temp = np.std(X_train_l, axis = 0)\n",
    "for i in range(len(temp)):\n",
    "    if temp[i]==0.: #or math.isnan(temp[i]):\n",
    "        temp[i]=1\n",
    "\n",
    "X_val /= temp\n",
    "X_test /= temp\n",
    "X_train_l /= temp\n",
    "X_train_ul /= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_l.shape\n",
    "y_train_l.shape\n",
    "#y_val.shape\n",
    "#X_val.shape\n",
    "#len(X_train_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import *\n",
    "import theano.tensor as T\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import lasagne\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label for dadef train_NN(num_epochs=500, width = 100, d_i = 0.3, d_h = 0.5, l_r = 0.01, la1p = 0.1, la2p = 0.1, la3p = 0.5):\n",
    "    \n",
    "    input_var = T.matrix('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    \n",
    "    print(\"Building model and compiling functions...\")\n",
    "    \n",
    "    layer_in = lasagne.layers.InputLayer(shape=(None, len(X_train_l[0]) ), input_var=input_var)\n",
    "    if d_i:\n",
    "        layer_in = lasagne.layers.dropout(layer_in, p=d_i)\n",
    "    \n",
    "    # Hidden layers and dropout:\n",
    "    \n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    layer1 = lasagne.layers.DenseLayer(layer_in, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer1 = lasagne.layers.dropout(layer1, p=d_h)\n",
    "      \n",
    "    layer2 = lasagne.layers.DenseLayer(layer1, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer2 = lasagne.layers.dropout(layer2, p=d_h)\n",
    "    \"\"\"      \n",
    "    layer3 = lasagne.layers.DenseLayer(layer2, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer3 = lasagne.layers.dropout(layer3, p=d_h)\n",
    "    \n",
    "    layer4 = lasagne.layers.DenseLayer(layer3, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer4 = lasagne.layers.dropout(layer4, p=d_h)\n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer5 = lasagne.layers.dropout(layer5, p=d_h)\n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer6 = lasagne.layers.dropout(layer6, p=d_h)\n",
    "    \n",
    "    layer7 = lasagne.layers.DenseLayer(layer6, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer7 = lasagne.layers.dropout(layer7, p=d_h)\n",
    "    \n",
    "    layer8 = lasagne.layers.DenseLayer(layer7, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer8 = lasagne.layers.dropout(layer8, p=d_h)\n",
    "    \n",
    "    layer9 = lasagne.layers.DenseLayer(layer8, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer9 = lasagne.layers.dropout(layer9, p=d_h)\n",
    "        \n",
    "    layer10 = lasagne.layers.DenseLayer(layer9, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer10 = lasagne.layers.dropout(layer10, p=d_h)\"\"\"\n",
    "    \n",
    "    #layer3 = lasagne.layers.DenseLayer(layer2, width, nonlinearity=nonlin)\n",
    "    #if d_h:\n",
    "    #    layer3 = lasagne.layers.dropout(layer3, p=d_h)\n",
    "        \n",
    "    #layer4 = lasagne.layers.DenseLayer(layer3, width, nonlinearity=nonlin)\n",
    "    #if d_h:\n",
    "    #    layer4 = lasagne.layers.dropout(layer4, p=d_h)\n",
    "        \n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(layer2, 10, nonlinearity=softmax)\n",
    "    \n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    #layers = {layer1: la1p, layer2: la2p, network: la3p}\n",
    "    #l2_penalty_1 = lasagne.regularization.regularize_layer_params_weighted({layer1:la1p}, lasagne.regularization.l2)\n",
    "    #l2_penalty = lasagne.regularization.regularize_layer_params(network, lasagne.regularization.l2)*1e-03\n",
    "    #loss = loss.mean() + l2_penalty + l1_penalty\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=l_r, momentum=0.9)\n",
    "    \n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "    #test_loss = test_loss.mean() + l2_penalty + l1_penalty\n",
    "    test_loss = test_loss.mean()\n",
    "    \n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    \n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    global percs\n",
    "    percs = array([])\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch in iterate_minibatches(X_train_l, y_train_l, 100, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 100, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        perc = val_acc / val_batches\n",
    "        percs = append(percs, perc)\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(perc * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, zeros(len(X_test)), 100, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "    print(\"Percentages average:\\t\\t\\t{:.5f}\".format(mean(percs)))\n",
    "    print(\"\\a\")\n",
    "    global result\n",
    "    result = lasagne.layers.get_output(network, X_test)\n",
    "    \"\"\"print (perc*100)\"\"\"\n",
    "    last=len(percs)\n",
    "    avg=(percs[last-1]+percs[last-2]+percs[last-3]+perc)/4\n",
    "    return avg*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 30 took 0.121s\n",
      "  training loss:\t\t0.635595\n",
      "  validation loss:\t\t0.426946\n",
      "  validation accuracy:\t\t91.40 %\n",
      "Epoch 2 of 30 took 0.150s\n",
      "  training loss:\t\t0.268749\n",
      "  validation loss:\t\t0.309868\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 3 of 30 took 0.126s\n",
      "  training loss:\t\t0.182039\n",
      "  validation loss:\t\t0.262177\n",
      "  validation accuracy:\t\t92.60 %\n",
      "Epoch 4 of 30 took 0.161s\n",
      "  training loss:\t\t0.136266\n",
      "  validation loss:\t\t0.263259\n",
      "  validation accuracy:\t\t92.80 %\n",
      "Epoch 5 of 30 took 0.133s\n",
      "  training loss:\t\t0.083796\n",
      "  validation loss:\t\t0.330055\n",
      "  validation accuracy:\t\t92.60 %\n",
      "Epoch 6 of 30 took 0.159s\n",
      "  training loss:\t\t0.082024\n",
      "  validation loss:\t\t0.243271\n",
      "  validation accuracy:\t\t92.40 %\n",
      "Epoch 7 of 30 took 0.129s\n",
      "  training loss:\t\t0.047833\n",
      "  validation loss:\t\t0.303424\n",
      "  validation accuracy:\t\t92.40 %\n",
      "Epoch 8 of 30 took 0.171s\n",
      "  training loss:\t\t0.048464\n",
      "  validation loss:\t\t0.348182\n",
      "  validation accuracy:\t\t92.40 %\n",
      "Epoch 9 of 30 took 0.125s\n",
      "  training loss:\t\t0.032294\n",
      "  validation loss:\t\t0.263871\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 10 of 30 took 0.144s\n",
      "  training loss:\t\t0.029635\n",
      "  validation loss:\t\t0.345296\n",
      "  validation accuracy:\t\t92.60 %\n",
      "Epoch 11 of 30 took 0.123s\n",
      "  training loss:\t\t0.018770\n",
      "  validation loss:\t\t0.332508\n",
      "  validation accuracy:\t\t93.20 %\n",
      "Epoch 12 of 30 took 0.245s\n",
      "  training loss:\t\t0.009837\n",
      "  validation loss:\t\t0.330250\n",
      "  validation accuracy:\t\t92.40 %\n",
      "Epoch 13 of 30 took 0.709s\n",
      "  training loss:\t\t0.011487\n",
      "  validation loss:\t\t0.354440\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 14 of 30 took 0.435s\n",
      "  training loss:\t\t0.006040\n",
      "  validation loss:\t\t0.336330\n",
      "  validation accuracy:\t\t93.40 %\n",
      "Epoch 15 of 30 took 0.242s\n",
      "  training loss:\t\t0.001461\n",
      "  validation loss:\t\t0.339760\n",
      "  validation accuracy:\t\t93.40 %\n",
      "Epoch 16 of 30 took 0.122s\n",
      "  training loss:\t\t0.001880\n",
      "  validation loss:\t\t0.350093\n",
      "  validation accuracy:\t\t93.40 %\n",
      "Epoch 17 of 30 took 0.141s\n",
      "  training loss:\t\t0.000811\n",
      "  validation loss:\t\t0.355130\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 18 of 30 took 0.123s\n",
      "  training loss:\t\t0.000545\n",
      "  validation loss:\t\t0.354753\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 19 of 30 took 0.144s\n",
      "  training loss:\t\t0.000459\n",
      "  validation loss:\t\t0.357300\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 20 of 30 took 0.225s\n",
      "  training loss:\t\t0.000401\n",
      "  validation loss:\t\t0.359473\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 21 of 30 took 0.315s\n",
      "  training loss:\t\t0.000364\n",
      "  validation loss:\t\t0.362322\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 22 of 30 took 0.321s\n",
      "  training loss:\t\t0.000334\n",
      "  validation loss:\t\t0.364274\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 23 of 30 took 0.264s\n",
      "  training loss:\t\t0.000311\n",
      "  validation loss:\t\t0.366209\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 24 of 30 took 0.195s\n",
      "  training loss:\t\t0.000289\n",
      "  validation loss:\t\t0.366801\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 25 of 30 took 0.432s\n",
      "  training loss:\t\t0.000271\n",
      "  validation loss:\t\t0.369005\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 26 of 30 took 0.135s\n",
      "  training loss:\t\t0.000255\n",
      "  validation loss:\t\t0.369737\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 27 of 30 took 0.251s\n",
      "  training loss:\t\t0.000242\n",
      "  validation loss:\t\t0.370768\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 28 of 30 took 0.140s\n",
      "  training loss:\t\t0.000229\n",
      "  validation loss:\t\t0.373529\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 29 of 30 took 0.158s\n",
      "  training loss:\t\t0.000220\n",
      "  validation loss:\t\t0.374604\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Epoch 30 of 30 took 0.135s\n",
      "  training loss:\t\t0.000208\n",
      "  validation loss:\t\t0.376255\n",
      "  validation accuracy:\t\t93.00 %\n",
      "Final results:\n",
      "  test loss:\t\t\t26.884028\n",
      "  test accuracy:\t\t9.91 %\n",
      "Percentages average:\t\t\t0.92840\n",
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l_r_range_2=np.linspace(0.1,0.2,30)\n",
    "#for l_r in l_r_range_2:\n",
    "train_NN(num_epochs=30, width = 200, d_i = 0, d_h = 0, l_r = 0.1, la1p = 0.5, la2p = 0.5, la3p = 0.5)\n",
    "#    print(l_r,max(percs))\n",
    "#    max_array.append(max(percs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f1c978fd6d8>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQ0x9CWpIYa+JDXE0Jekhhj6ktSQ/wcXcWy81xvUbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c96f8b6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scatter(l_r_range+l_range_2,max_array)\n",
    "scatter(arange(len(percs)),percs)\n",
    "#print(max(percs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f1c9848c748>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf96a7qPGd0/EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c98514f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(np.append(l_r_range,l_r_range_2),max_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = result.eval()\n",
    "sum(final[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3432 index: 2503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output = list([])\n",
    "p_output = list([])\n",
    "for i in arange(len(final)):\n",
    "    my_list = final[i,:]\n",
    "    max_index = my_list.argmax()\n",
    "    p_output.append(my_list[max_index])\n",
    "    y_output.append(max_index)\n",
    "p_output = asarray(p_output)\n",
    "mini = p_output.argmin()\n",
    "print('{:.4f} index: {:d}'.format(p_output[mini],mini))\n",
    "len(y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result_5.csv', 'w') as fp:\n",
    "    a = csv.writer(fp, delimiter=',')\n",
    "    a.writerow(('Id','y'))\n",
    "    a.writerows(zip(ids,y_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evecs = np.float32(zeros([116,116]))\n",
    "evals = np.float32(zeros([116]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prog = array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "for s in arange(116):\n",
    "    print(s)\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 116])\n",
    "    v = tf.Variable( tf.random_normal([116, 1], mean=0.1, stddev=0.1), trainable=True )\n",
    "    v = tf.div(v,tf.sqrt(tf.matmul(tf.transpose(v),v)))\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in arange(1000):\n",
    "        print(i)\n",
    "        loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v)) + np.sum(evals[j]*tf.matmul(reshape(evecs[j],[116,1]).T,v)*tf.matmul(reshape(evecs[s],[116,1]).T,v) for j in arange(s))\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.000001).minimize(loss)\n",
    "        _, lo = sess.run([train_step, loss], feed_dict={x:X_train_l})\n",
    "        evecs[s] = reshape(v.eval(),[116])\n",
    "        evals[s] = lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -76231.46875, -152463.03125, -304926.03125, -609852.125  ,\n",
       "       -653791.375  ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ,\n",
       "             0.     ,       0.     ,       0.     ,       0.     ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_step = tf.train.GradientDescentOptimizer(0.000001).minimize(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_step.run(feed_dict={x: X_train_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_, lo = sess.run([train_step, l], feed_dict={x:X_train_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prog = array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected begin[0] in [0, 116], but got 118\n\t [[Node: Slice_355 = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, Slice_355/begin, Slice_355/size)]]\nCaused by op 'Slice_355', defined at:\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-2915027bcca1>\", line 1, in <module>\n    loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v)) + np.sum(evals[j]*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v)*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v) for j in arange(k))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/numpy/core/fromnumeric.py\", line 1825, in sum\n    res = _sum_(a)\n  File \"<ipython-input-17-2915027bcca1>\", line 1, in <genexpr>\n    loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v)) + np.sum(evals[j]*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v)*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v) for j in arange(k))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 610, in <lambda>\n    setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 625, in _RunOp\n    return getattr(ops.Tensor, operator)(a._AsTensor(), b)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 167, in _SliceHelper\n    sliced = slice(tensor, indices, sizes)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 217, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1318, in _slice\n    name=name)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatusNotOK\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatusNotOK\u001b[0m: Invalid argument: Expected begin[0] in [0, 116], but got 118\n\t [[Node: Slice_355 = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, Slice_355/begin, Slice_355/size)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c24683d96c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train_l\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[0;32m--> 659\u001b[0;31m                                             e.code)\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected begin[0] in [0, 116], but got 118\n\t [[Node: Slice_355 = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1/read, Slice_355/begin, Slice_355/size)]]\nCaused by op 'Slice_355', defined at:\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-2915027bcca1>\", line 1, in <module>\n    loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v)) + np.sum(evals[j]*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v)*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v) for j in arange(k))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/numpy/core/fromnumeric.py\", line 1825, in sum\n    res = _sum_(a)\n  File \"<ipython-input-17-2915027bcca1>\", line 1, in <genexpr>\n    loss = - tf.matmul(tf.transpose(tf.matmul(x,v)),tf.matmul(x,v)) + np.sum(evals[j]*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v)*tf.matmul(tf.transpose(tf.reshape(evecs[j,:],[116,1])),v) for j in arange(k))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 610, in <lambda>\n    setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b))\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 625, in _RunOp\n    return getattr(ops.Tensor, operator)(a._AsTensor(), b)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 167, in _SliceHelper\n    sliced = slice(tensor, indices, sizes)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 217, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1318, in _slice\n    name=name)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Camilo/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "for k in arange(116):\n",
    "    for i in arange(1000):\n",
    "        _, lo = sess.run([train_step, loss], feed_dict={x:X_train_l})\n",
    "        prog = np.append(prog, lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x118b74b70>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEACAYAAACQx1DIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGhpJREFUeJzt3XmQXeV95vHvI4lGYpGQcJDKWggUkhFjgt0MIuWMxzck\nQiJTQUpiQFOpSE40iy3FpOyJBxNcSAp2hWHGtuypAWccbEBjo2CyIFcULRTqqSIRRmIZYUsWnWCw\nurHAaGkWW6DlN3+ct9Gh062W+p6+pznn+VTd0nt/Z+G9x7Keft/3nNuKCMzMzIoyquwOmJlZtThY\nzMysUA4WMzMrlIPFzMwK5WAxM7NCOVjMzKxQTQWLpDsk7ZL0tKS/kjQ+t+1mSZ1p+9W5erukHZKe\nlbQ6V2+TtDYds1XSjNy2JWn/3ZIWN9NnMzMbXs2OWDYB/yoiPgB0AjcDSLoEuB6YDVwD3ClJ6Zi7\ngKURMQuYJWleqi8F9kfETGA1cEc610TgVuAK4EpghaQJTfbbzMyGSVPBEhEPR8Sx9PYxYFpqXwus\njYgjEfE8WejMkTQFODsitqX97gMWpvYC4N7UfhC4KrXnAZsioiciDpKF2fxm+m1mZsOnyDWWPwDW\np/ZUYE9uW3eqTQW6cvWuVHvHMRFxFOiRNOkE5zIzsxFozGA7SNoMTM6XgABuiYjvpn1uAQ5HxP0F\n9k2D72JmZiPNoMESEXNPtF3Sx4Df4PjUFWSjium599NSbaB6/pgXJY0GxkfEfkndQKPPMVsG6Iu/\n+MzMbAgiorAf5pu9K2w+8Bng2oh4M7dpHbAo3el1AXAR8HhE7CWb4pqTFvMXAw/ljlmS2tcBj6T2\nRmCupAlpIX9uqvUrIvyKYMWKFaX3YaS8fC18LXwtTvwq2qAjlkH8T6AN2Jxu+nosIpZFxE5JDwA7\ngcPAsjje++XAPcBYYH1EbEj1u4E1kjqBfcAigIg4IOk2YDvZFNyqyBbxzcxsBGoqWCK7NXigbX8G\n/Fk/9SeAS/upv0l2i3J/57qHLIzMzGyE85P3FdVoNMruwojha3Gcr8VxvhbDR8Mxv1YWSVGlz2Nm\n1gqSiJGyeG9mZtaXg8XMzArlYDEzs0I5WMzMrFAOFjMzK5SDxczMCuVgMTOzQjlYzMysUJULlrfe\nKrsHZmb1Vrlgef31sntgZlZvDhYzMytU5YLltdfK7oGZWb1VLlg8YjEzK5eDxczMClW5YPFUmJlZ\nuSoXLB6xmJmVq3LB4hGLmVm5KhcsHrGYmZXLwWJmZoWqXLB4KszMrFyVCxaPWMzMyuVgMTOzQlUu\nWDwVZmZWrsoFi0csZmblqlyweMRiZlauygWLRyxmZuVqKlgk/amk/yfpKUkbJE3JbbtZUqekXZKu\nztXbJe2Q9Kyk1bl6m6S16Zitkmbkti1J+++WtPhEfXKwmJmVSxEx9IOlsyLi9dT+JHBJRHxC0iXA\nt4ArgGnAw8DMiAhJ3wP+MCK2SVoPfCUiNkr6BHBpRCyTdAPwWxGxSNJEYDvQDgh4AmiPiJ5++hPj\nxwc9/2KLmZkNRBIRoaLO19SIpTdUkjOBY6l9LbA2Io5ExPNAJzAnjWjOjohtab/7gIWpvQC4N7Uf\nBK5K7XnApojoiYiDwCZg/kB9ev11aCIrzcysSWOaPYGkzwOLgYPAr6byVGBrbrfuVDsCdOXqXane\ne8wegIg4KqlH0qR8vc+5+nXaaXDoEIwbN+SPZGZmTRh0xCJpc1oT6X09k/78TYCI+FxEzCCb+vpk\ngX0b0rDs7LN9Z5iZWZkGHbFExNyTPNe3gb8DVpKNKqbntk1LtYHq5La9KGk0MD4i9kvqBhp9jtky\nUCcOH17JF74AEydCo9Gg0WgMtKuZWS11dHTQ0dExbOdvdvH+ooj4p9T+JPDhiLg+t3h/Jdm01WaO\nL94/BtwIbCMLoq9GxAZJy4D3p8X7RcDCfhbvR6X25Wm9pW9/4tJLgzVr4LLLhvyxzMxqpejF+2bX\nWG6XNIts0f4F4OMAEbFT0gPATuAwsCyOJ9hy4B5gLLA+Ijak+t3AGkmdwD5gUTrXAUm3kQVKAKv6\nC5VeZ53lW47NzMrU1IhlpJEUc+cGn/40zB/wvjEzM8sbUbcbj0RnnQVvvFF2L8zM6quSweKpMDOz\n8jhYzMysUJUMFk+FmZmVp3LBcuaZHrGYmZWpcsHiqTAzs3I5WMzMrFCVDBavsZiZladyweI1FjOz\nclUuWDwVZmZWLgeLmZkVqpLB4jUWM7PyVDJYPGIxMytP5YLFi/dmZuWqXLB4xGJmVq7KBcvYsXD4\nMBw5UnZPzMzqqXLBInkB38ysTJULFvA6i5lZmSoZLF5nMTMrj4PFzMwKVdlg8RqLmVk5KhssHrGY\nmZWjksHixXszs/JUMlg8YjEzK09lg8VrLGZm5ahssHjEYmZWjkoGi9dYzMzKU8lg8YjFzKw8lQ0W\nr7GYmZWjkGCR9F8kHZM0KVe7WVKnpF2Srs7V2yXtkPSspNW5epuktemYrZJm5LYtSfvvlrR4sP54\nxGJmVp6mg0XSNGAu8EKuNhu4HpgNXAPcKUlp813A0oiYBcySNC/VlwL7I2ImsBq4I51rInArcAVw\nJbBC0oQT9clrLGZm5SlixPJl4DN9aguAtRFxJCKeBzqBOZKmAGdHxLa0333Awtwx96b2g8BVqT0P\n2BQRPRFxENgEzD9RhzxiMTMrT1PBIulaYE9EPNNn01RgT+59d6pNBbpy9a5Ue8cxEXEU6ElTawOd\na0BeYzEzK8+YwXaQtBmYnC8BAXwO+BOyabDhoMF3+ZdWrlzJT38KP/oRdHQ0aDQaBXfLzOzdraOj\ng46OjmE7vyJiaAdK7wceBn5GFgLTyEYTc4A/AIiI29O+G4AVZOswWyJidqovAj4SEZ/o3Scividp\nNPCTiDgv7dOIiI+nY76WzvGX/fQpIoI9e+BDH4I9e/ruYWZmfUkiIob0w3x/hjwVFhHfj4gpEXFh\nRFxANq31wYh4GVgH3JDu9LoAuAh4PCL2kk1xzUmL+YuBh9Ip1wFLUvs64JHU3gjMlTQhLeTPTbUB\nefHezKw8g06FnYIgTV9FxE5JDwA7gcPAsjg+NFoO3AOMBdZHxIZUvxtYI6kT2AcsSuc6IOk2YHv6\nb6xKi/gD8hqLmVl5hjwVNhL1ToUBtLVlo5a2tpI7ZWY2wo2YqbCRzrccm5mVo7LB4nUWM7NyVDZY\nPGIxMytHpYPFC/hmZq1X6WDxiMXMrPUcLGZmVqjKBosX783MylHZYPEai5lZOSodLB6xmJm1noPF\nzMwKVdlg8RqLmVk5KhssXmMxMytHpYPFIxYzs9ZzsJiZWaEqGyxeYzEzK0dlg8VrLGZm5ah0sHjE\nYmbWeg4WMzMrlIPFzMwKVdlgOfNMr7GYmZWh0sHy+usQUXZPzMzqpbLBMmYMtLXBoUNl98TMrF4q\nGyzgdRYzszJUOlj8kKSZWetVOlj8kKSZWetVPlg8YjEzay0Hi5mZFarSweI1FjOz1msqWCStkNQl\n6cn0mp/bdrOkTkm7JF2dq7dL2iHpWUmrc/U2SWvTMVslzchtW5L23y1p8cn2z2ssZmatV8SI5UsR\n0Z5eGwAkzQauB2YD1wB3SlLa/y5gaUTMAmZJmpfqS4H9ETETWA3ckc41EbgVuAK4ElghacLJdMxT\nYWZmrVdEsKif2gJgbUQciYjngU5gjqQpwNkRsS3tdx+wMHfMvan9IHBVas8DNkVET0QcBDYBb4+M\nTsTBYmbWekUEyx9KelrSX+RGElOBPbl9ulNtKtCVq3el2juOiYijQI+kSSc416AcLGZmrTdmsB0k\nbQYm50tAALcAdwJ/GhEh6fPAF4H/UFDf+hsJDWrlypVvt/fubTBhQqOg7piZVUNHRwcdHR3Ddv5B\ngyUi5p7kub4OfDe1u4HpuW3TUm2gev6YFyWNBsZHxH5J3UCjzzFbBupEPljuvBO+//2T7L2ZWU00\nGg0ajcbb71etWlXo+Zu9K2xK7u1vA73/jK8DFqU7vS4ALgIej4i9ZFNcc9Ji/mLgodwxS1L7OuCR\n1N4IzJU0IS3kz021QXkqzMys9QYdsQziDkkfAI4BzwP/GSAidkp6ANgJHAaWRbz9BfbLgXuAscD6\n3jvJgLuBNZI6gX3AonSuA5JuA7aTTcGtSov4g3KwmJm1nqJCv7BEUuQ/z8aN8KUvZX+amVn/JBER\nQ1rX7k+ln7z3iMXMrPUcLGZmVigHi5mZFaryweLvCjMza61KB4u/3djMrPUqHSxnnAE//zkcO1Z2\nT8zM6qPSwTJqFIwbBz/7Wdk9MTOrj0oHC3idxcys1SofLF5nMTNrrcoHi285NjNrLQeLmZkVysFi\nZmaFqkWwvPZa2b0wM6uPygfLhAnQ01N2L8zM6qPywXLOOQ4WM7NWqnyweMRiZtZaDhYzMytULYLl\n4En9ImMzMytCLYLFIxYzs9ZxsJiZWaEcLGZmVigHi5mZFcrBYmZmhapNsESU3RMzs3qofLCcfjqM\nHg2HDpXdEzOzeqh8sICnw8zMWqk2weKHJM3MWqM2weIRi5lZazQdLJI+KWmXpGck3Z6r3yypM227\nOldvl7RD0rOSVufqbZLWpmO2SpqR27Yk7b9b0uJT7aODxcysdcY0c7CkBvCbwKURcUTSe1J9NnA9\nMBuYBjwsaWZEBHAXsDQitklaL2leRGwElgL7I2KmpBuAO4BFkiYCtwLtgIAnJD0UEScdFQ4WM7PW\naXbE8gng9og4AhARr6T6AmBtRByJiOeBTmCOpCnA2RGxLe13H7Awd8y9qf0gcFVqzwM2RURPRBwE\nNgHzT6WTDhYzs9ZpNlhmAf9W0mOStki6PNWnAnty+3Wn2lSgK1fvSrV3HBMRR4EeSZNOcK6T5mAx\nM2udQafCJG0GJudLQACfS8dPjIhflnQF8B3gwoL6pqEctHLlyrfbjUaDRqPhYDEzy+no6KCjo2PY\nzj9osETE3IG2Sfo48Ndpv22Sjko6l2xUMSO367RU6wam91Mnt+1FSaOB8RGxX1I30OhzzJaB+pQP\nll7nnAPPPTfQEWZm9dL7Q3evVatWFXr+ZqfC/pa0FiJpFtAWEfuAdcAN6U6vC4CLgMcjYi/ZFNcc\nSQIWAw+lc60DlqT2dcAjqb0RmCtpQlrIn5tqJ83PsZiZtU5Td4UB3wS+IekZ4E2yoCAidkp6ANgJ\nHAaWpTvCAJYD9wBjgfURsSHV7wbWSOoE9gGL0rkOSLoN2E42BbcqLeKftIkT4cCBoX9IMzM7eYoK\nfTujpOjv8zz6KNx0E/zDP5TQKTOzEU4SETGkde3+1OLJ+3PPhX37yu6FmVk9OFjMzKxQtZgKO3wY\nxo2Dt96CUbWIUjOzk+epsCE47TQ480x49dWye2JmVn21CBbwdJiZWas4WMzMrFC1CZZJkxwsZmat\nUJtgOfdc2L+/7F6YmVVfrYLFIxYzs+HnYDEzs0LVJli8xmJm1hq1CZb3vAdeeWXw/czMrDm1CZbz\nzoOXXy67F2Zm1VebYJkyBfbuLbsXZmbVV5tgmTwZXnqp7F6YmVVfLb6EEuDYMTj9dHjjDWhra3HH\nzMxGMH8J5RCNGgW/8AteZzEzG261CRbwOouZWSvUKli8zmJmNvxqFSwesZiZDb9aBYtHLGZmw69W\nweIRi5nZ8KtdsPzkJ2X3wsys2moVLNOnw549ZffCzKzaahUs558PP/5x2b0wM6u22jx5D3D0KIwb\nB6+9lj2Fb2ZmfvK+KaNHw3vfC93dZffEzKy6ahUsADNmeDrMzGw4NRUsktZKejK9fiTpydy2myV1\nStol6epcvV3SDknPSlqdq7el83VK2ippRm7bkrT/bkmLm+nzjBnwwgvNnMHMzE5kTDMHR8Si3rak\n/wEcTO3ZwPXAbGAa8LCkmWkB5C5gaURsk7Re0ryI2AgsBfZHxExJNwB3AIskTQRuBdoBAU9Ieigi\neobSZy/gm5kNryKnwq4Hvp3aC4C1EXEkIp4HOoE5kqYAZ0fEtrTffcDC3DH3pvaDwFWpPQ/YFBE9\nEXEQ2ATMH2onPWIxMxtehQSLpA8DeyPiuVSaCuSfGOlOtalAV67elWrvOCYijgI9kiad4FxDcuGF\n8M//PNSjzcxsMINOhUnaDEzOl4AAbomI76bavwfuL7hvhd36lve+98Hu3cNxZjMzg5MIloiYe6Lt\nkkYDv022BtKrG5ieez8t1Qaq5495MZ1zfETsl9QNNPocs2Wg/qxcufLtdqPRoNFovGP7tGnQ0wOv\nvgrjx5/ok5mZVVNHRwcdHR3Ddv6mH5CUNB+4KSJ+NVe7BPgWcCXZtNVmYGZEhKTHgBuBbcDfAV+N\niA2SlgHvj4hlkhYBCyOid/F+O1lwjUrty9N6S9++nPAByV7t7fDnfw5XXNHURzczq4SiH5Bs6q6w\n5Ab6TINFxE5JDwA7gcPAsty/+MuBe4CxwPqI2JDqdwNrJHUC+4BF6VwHJN1GFigBrOovVE7F+94H\nP/yhg8XMbDjU6itdeq1aBYcPw+c/34JOmZmNcP5KlwJcfDHs3Fl2L8zMqqmWwdLeDk88UXYvzMyq\nqZbBctFF2V1hL79cdk/MzKqnlsEiweWXw7Ztg+9rZmanppbBAtkdYdu3l90LM7PqqW2wzJkD//iP\nZffCzKx6anm7McDBgzB9erbOMm7cMHfMzGwE8+3GBTnnHPilX4JHHy27J2Zm1VLbYAGYNw82biy7\nF2Zm1VLrYFmwAL7zHTh2rOyemJlVR62D5bLLYNIkGMYv+TQzq51aBwvAxz4GX/962b0wM6uO2t4V\n1uvVV2HmTNiyBS65ZJg6ZmY2gvmusIKNHw9//Mdw001QoYw1MytN7YMF4MYboavLU2JmZkUo4hd9\nveudfjrcfz80Gtli/kc/WnaPzMzevTxiSS6+GP7+7+HTn4bly+Gll8rukZnZu5ODJeeDH4SnnoLR\no7Og+Z3fgTvvhMceg5/+1M+7mJmdjNrfFTaQfftg3brsiyqffBJeeAF6euDcc+GMM2Ds2GwKbexY\nOO207Kv4pd5+HP9zoHbfmplZWTZuLPauMAfLKXjrLXjlFfj5z+HNN+HQoezPt946fkdZ/s+B2n1r\nZmZluuYaB8uAhjtYzMyqyM+xmJnZiOZgMTOzQjlYzMysUA4WMzMrlIPFzMwK5WAxM7NCOVjMzKxQ\nTQWLpMskbZX0lKTHJf3r3LabJXVK2iXp6ly9XdIOSc9KWp2rt0lam47ZKmlGbtuStP9uSYub6bOZ\nmQ2vZkcsdwArIuKDwArgvwNIugS4HpgNXAPcKb395SV3AUsjYhYwS9K8VF8K7I+ImcDqdG4kTQRu\nBa4ArgRWSJrQZL8rr8O/b/ltvhbH+Voc52sxfJoNlmNA7z/y5wDdqX0tsDYijkTE80AnMEfSFODs\niNiW9rsPWJjaC4B7U/tB4KrUngdsioieiDgIbALmN9nvyvP/aY7ztTjO1+I4X4vh0+zvY/kUsFHS\nFwEBH0r1qcDW3H7dqXYE6MrVu1K995g9ABFxVFKPpEn5ep9zmZnZCDRosEjaDEzOl4AAbgF+Hfij\niPhbSR8FvgHMLahv/t5fM7N3o4gY8gs42N974LPATbn6BrL1kSnArlx9EXBXfp/UHg28nNvna7lj\nvgbcMEB/wi+//PLLr1N/NZMFfV/NToV1S/pIRPxfSb9GtpYCsA74lqQvk01bXQQ8HhGRprjmANuA\nxcBXc8csAb4HXAc8kuobgS+kBftRZCOiz/bXmSK/ndPMzIam2WD5j8BXJY0GDgH/CSAidkp6ANgJ\nHAaW5b7PfjlwDzAWWB8RG1L9bmCNpE5gH9lIhYg4IOk2YDtZsq5Ki/hmZjYCVer3sZiZWfkq8+S9\npPmSfpgepLyp7P4MN0nTJD0i6QeSnpF0Y6pPlLQpPUy6Mf/Mz0APrVaBpFGSnpS0Lr2v5XUAkDRB\n0nfS5/uBpCvreD0kfUrS99MD2d9KD2HX5jpIulvSS5J25Gqn/PkHeqj9hIpcsCnrRRaQ/wScD5wG\nPA1cXHa/hvkzTwE+kNpnAbuBi4H/BvzXVL8JuD21LwGeIpv+/MV0vVT25yjwenwK+D/AuvS+ltch\nfcZ7gN9P7TFkz5rV6noA7wWeA9rS+78kW8OtzXUA/g3wAWBHrnbKn59s3fuK1F4PzBvsv12VEcsc\noDMiXoiIw8BasgcuKysi9kbE06n9OrALmMY7HzS9l+MPoPb70GpLOz1MJE0DfgP4i1y5dtcBQNJ4\n4MMR8U2A9Dl7qOf1GA2cKWkMMI7sGbjaXIeIeBQ40Kd8Sp9/kIfaB1SVYOn7EGX+wcvKk/SLZD+Z\nPAZMjoiXIAsf4Ly0W5UfNP0y8Bmymzt61fE6AFwAvCLpm2lq8H9LOoOaXY+IeBH4IvBjss/UExEP\nU7Pr0I/zTvHzT2Xgh9oHVJVgqS1JZ5F9Bc4fpZFL37sxKn13hqR/B7yURm8nut280tchZwzQDvyv\niGgH3iC7Pb9ufy/OIfvp/HyyabEzJf0uNbsOJ2FYPn9VgqUbmJF7P43j31tWWWmI/yCwJiIeSuWX\nJE1O26cAL6d6NzA9d3hVrtGvANdKeg64H7hK0hpgb82uQ68uYE9EbE/v/4osaOr29+LXgeciYn9E\nHAX+huwrp+p2Hfo61c8/pOtSlWDZBlwk6XxJbWTPwKwruU+t8A1gZ0R8JVdbB3wstZcAD+Xqi9Kd\nMReQHlptVUeHS0T8SUTMiIgLyf53fyQifg/4LjW6Dr3SNMceSbNS6deAH1CzvxdkU2C/LGmsJJFd\nh53U7zqId47kT+nzp+myHklz0nVcnDtmYGXfuVDgHRDzye6M6gQ+W3Z/WvB5fwU4SnYH3FPAk+ka\nTAIeTtdiE3BO7pibye722AVcXfZnGIZr8hGO3xVW5+twGdkPW08Df012V1jtrgfZr/LYBewgW6g+\nrU7XAfg28CLwJlnQ/j4w8VQ/P3A58Ez6t/UrJ/Pf9gOSZmZWqKpMhZmZ2QjhYDEzs0I5WMzMrFAO\nFjMzK5SDxczMCuVgMTOzQjlYzMysUA4WMzMr1P8HqQSk0SGa67cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1187f6e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-23606.640625  , -25373.54492188, -27208.50390625, -29104.51953125,\n",
       "       -31053.        , -33044.2578125 , -35067.87890625, -37112.4453125 ,\n",
       "       -39166.07421875, -41216.73828125, -43252.5546875 , -45261.59765625,\n",
       "       -47232.7890625 , -49155.99609375, -51021.7734375 , -52822.00390625,\n",
       "       -54550.2265625 , -56200.73828125, -57769.58203125, -59253.6875    ,\n",
       "       -60651.62890625, -61963.3359375 , -63188.9140625 , -64330.0390625 ,\n",
       "       -65389.21484375, -66368.78125   , -67272.5703125 , -68103.9453125 ,\n",
       "       -68866.7890625 , -69565.6484375 , -70203.6171875 , -70785.875     ,\n",
       "       -71315.78125   , -71797.6015625 , -72234.703125  , -72631.1328125 ,\n",
       "       -72989.765625  , -73314.625     , -73607.65625   , -73872.578125  ,\n",
       "       -74111.375     , -74326.53125   , -74520.6171875 , -74695.09375   ,\n",
       "       -74852.359375  , -74993.7578125 , -75120.6796875 , -75234.8984375 ,\n",
       "       -75337.640625  , -75429.6953125 , -75512.3359375 , -75586.7890625 ,\n",
       "       -75653.453125  , -75713.1953125 , -75766.859375  , -75815.1796875 ,\n",
       "       -75858.1328125 , -75896.875     , -75931.7109375 , -75962.9296875 ,\n",
       "       -75990.59375   , -76015.5234375 , -76037.921875  , -76058.2109375 ,\n",
       "       -76076.265625  , -76092.4453125 , -76106.78125   , -76119.6953125 ,\n",
       "       -76131.5703125 , -76141.8359375 , -76151.2109375 , -76159.6953125 ,\n",
       "       -76167.1328125 , -76173.859375  , -76180.0234375 , -76185.296875  ,\n",
       "       -76190.0078125 , -76194.1796875 , -76198.2421875 , -76201.7421875 ,\n",
       "       -76204.8671875 , -76207.671875  , -76210.2109375 , -76212.28125   ,\n",
       "       -76214.4375    , -76216.28125   , -76217.8046875 , -76219.265625  ,\n",
       "       -76220.421875  , -76221.734375  , -76222.640625  , -76223.6875    ,\n",
       "       -76224.59375   , -76225.2421875 , -76225.7734375 , -76226.4296875 ,\n",
       "       -76227.1875    , -76227.5703125 , -76228.0390625 , -76228.40625   ,\n",
       "       -76228.703125  , -76229.03125   , -76229.28125   , -76229.5078125 ,\n",
       "       -76229.59375   , -76229.8046875 , -76229.8984375 , -76230.140625  ,\n",
       "       -76230.265625  , -76230.546875  , -76230.640625  , -76230.78125   ,\n",
       "       -76230.9765625 , -76231.046875  , -76231.1015625 , -76231.1484375 ,\n",
       "       -76231.171875  , -76231.2890625 , -76231.234375  , -76231.265625  ,\n",
       "       -76231.3125    , -76231.375     , -76231.359375  , -76231.3671875 ,\n",
       "       -76231.4140625 , -76231.46875   , -76231.46875   , -76231.609375  ,\n",
       "       -76231.5859375 , -76231.6953125 , -76231.7421875 , -76231.8125    ,\n",
       "       -76231.8046875 , -76231.7109375 , -76231.6328125 , -76231.703125  ,\n",
       "       -76231.6328125 , -76231.6328125 , -76231.640625  , -76231.671875  ,\n",
       "       -76231.6640625 , -76231.640625  , -76231.6484375 , -76231.640625  ,\n",
       "       -76231.59375   , -76231.6328125 , -76231.6015625 , -76231.640625  ,\n",
       "       -76231.6953125 , -76231.6953125 , -76231.6171875 , -76231.6015625 ,\n",
       "       -76231.5703125 , -76231.5390625 , -76231.5546875 , -76231.5859375 ,\n",
       "       -76231.5703125 , -76231.6171875 , -76231.59375   , -76231.59375   ,\n",
       "       -76231.6171875 , -76231.6015625 , -76231.640625  , -76231.65625   ,\n",
       "       -76231.7265625 , -76231.703125  , -76231.6875    , -76231.6953125 ,\n",
       "       -76231.6640625 , -76231.703125  , -76231.703125  , -76231.6953125 ,\n",
       "       -76231.75      , -76231.7421875 , -76231.7265625 , -76231.7578125 ,\n",
       "       -76231.7578125 , -76231.7734375 , -76231.7734375 , -76231.7421875 ,\n",
       "       -76231.75      , -76231.7734375 , -76231.8125    , -76231.84375   ,\n",
       "       -76231.8046875 , -76231.8203125 , -76231.8125    , -76231.859375  ,\n",
       "       -76231.84375   , -76231.859375  , -76231.890625  , -76231.84375   ,\n",
       "       -76231.84375   , -76231.859375  , -76231.84375   , -76231.8359375 ,\n",
       "       -76231.8203125 , -76231.8125    , -76231.828125  , -76231.828125  ,\n",
       "       -76231.828125  , -76231.8203125 , -76231.828125  , -76231.8203125 ,\n",
       "       -76231.8203125 , -76231.8359375 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.7734375 , -76231.7890625 , -76231.7890625 , -76231.7890625 ,\n",
       "       -76231.796875  , -76231.8125    , -76231.796875  , -76231.8046875 ,\n",
       "       -76231.796875  , -76231.8125    , -76231.8046875 , -76231.796875  ,\n",
       "       -76231.796875  , -76231.78125   , -76231.78125   , -76231.796875  ,\n",
       "       -76231.796875  , -76231.8046875 , -76231.8046875 , -76231.796875  ,\n",
       "       -76231.796875  , -76231.8125    , -76231.8046875 , -76231.8125    ,\n",
       "       -76231.8125    , -76231.8046875 , -76231.796875  , -76231.8125    ,\n",
       "       -76231.8046875 , -76231.796875  , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.796875  , -76231.8203125 , -76231.8203125 , -76231.8203125 ,\n",
       "       -76231.8203125 , -76231.8203125 , -76231.8046875 , -76231.828125  ,\n",
       "       -76231.8125    , -76231.8046875 , -76231.8046875 , -76231.796875  ,\n",
       "       -76231.8046875 , -76231.796875  , -76231.796875  , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8125    , -76231.796875  , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8125    , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8125    , -76231.796875  , -76231.8125    , -76231.8203125 ,\n",
       "       -76231.8203125 , -76231.8203125 , -76231.8203125 , -76231.8203125 ,\n",
       "       -76231.8203125 , -76231.8203125 , -76231.8203125 , -76231.8203125 ,\n",
       "       -76231.8203125 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ,\n",
       "       -76231.8046875 , -76231.8046875 , -76231.8046875 , -76231.8046875 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000012]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(dot(v.eval().T,v.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030677897437792302"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(-prog[900])/9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin = dot(X_train_l,vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x119b6e4e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+8AAAE4CAYAAAAq3sKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSpJYzeZckSZIkqeX+OzxawQwkkpe/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a86f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(17,5))\n",
    "scatter(fin, zeros(len(fin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_4:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(eve,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evecs[0] = np.ones(116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
