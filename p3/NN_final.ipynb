{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'train']\n",
      "[u'test']\n"
     ]
    }
   ],
   "source": [
    "f_train = h5py.File('train.h5','r')\n",
    "f_test = h5py.File('test.h5','r')\n",
    "print(f_train.keys())\n",
    "print(f_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'axis0', u'axis1', u'block0_items', u'block0_values', u'block1_items', u'block1_values']\n",
      "[u'axis0', u'axis1', u'block0_items', u'block0_values']\n"
     ]
    }
   ],
   "source": [
    "a_train = f_train['train']\n",
    "a_test = f_test['test']\n",
    "print(a_train.keys())\n",
    "print(a_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45324, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a_train['block1_values']\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# axis0 -> Labels [shape (101,)]\n",
    "# axis1 -> id column [shape (45324,)]\n",
    "# block0_items -> traits labels [shape (100,)]\n",
    "# block0_values -> traits values [shape (45324,100)]\n",
    "# block1_items -> 'y' label\n",
    "# block1_values -> y column (without label) [shape (45324,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr = a_train['block0_values'][()]\n",
    "y_train = a_train['block1_values'][()]\n",
    "y_train = y_train[:,0]\n",
    "X_te = a_test['block0_values'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Shuffle\n",
    "c = zip(y_train, X_tr)\n",
    "random.shuffle(c)\n",
    "y_train, X_tr = zip(*c)\n",
    "y_train = asarray(y_train)\n",
    "X_tr = asarray(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_va = X_tr[:-5000], X_tr[-5000:]\n",
    "y_train, y_val = y_train[:-5000], y_train[-5000:]\n",
    "ids = a_test['axis1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Are there zero columns?\n",
    "def is_zero_vector(x):\n",
    "    count = 0\n",
    "    for i in arange(len(x)):\n",
    "        if x[i] == 0.:\n",
    "            count += 1\n",
    "    if count == len(x):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_i = list([])\n",
    "for k in arange(len(X_tr[0,:])):   \n",
    "    if is_zero_vector(X_tr[:,k]):\n",
    "        zero_i.append(k)\n",
    "X_tr = delete(X_tr, zero_i, 1)\n",
    "X_va = delete(X_va, zero_i, 1)\n",
    "X_te = delete(X_te, zero_i, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40324, 90)\n",
      "(8137, 90)\n",
      "(5000, 90)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_te.shape)\n",
    "print(X_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr -= np.mean(X_tr, axis = 0)\n",
    "X_va -= np.mean(X_tr, axis = 0)\n",
    "X_te -= np.mean(X_tr, axis = 0)\n",
    "X_tr /= np.std(X_tr, axis = 0)\n",
    "X_va /= np.std(X_tr, axis = 0)\n",
    "X_te /= np.std(X_tr, axis = 0)\n",
    "#print(is_zero_vector(X_tr[:,4]))\n",
    "#print(np.std(X_tr, axis = 0))\n",
    "#print(X_tr[:,4])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#X_train_c = X_train.reshape(len(X_train),1,20,5)\n",
    "#X_val_c = X_val.reshape(len(X_val),1,20,5)\n",
    "#X_test_c = X_test.reshape(len(X_test),1,20,5) \n",
    "\n",
    "if len(X_tr[0,:]) == 91:\n",
    "    new_col = ones(len(X_tr))\n",
    "    new_col = new_col.reshape((len(X_tr),1))\n",
    "    X_train = np.append(new_col,X_tr, 1)\n",
    "if len(X_va[0,:]) == 91:\n",
    "    new_col = ones(len(X_va))\n",
    "    new_col = new_col.reshape((len(X_va),1))\n",
    "    X_val = np.append(new_col,X_va, 1)\n",
    "if len(X_te[0,:]) == 91:\n",
    "    new_col = ones(len(X_te))\n",
    "    new_col = new_col.reshape((len(X_te),1))\n",
    "    X_test = np.append(new_col,X_te, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_tr\n",
    "X_test = X_te\n",
    "X_val = X_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "0.0\n",
      "(40324, 90)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0,:]))\n",
    "print(X_train[1,0])\n",
    "print(X_train.shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x105fe15d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e91a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(arange(100), y_train[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import *\n",
    "import theano.tensor as T\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_NN(num_epochs=500, width = 100, d_i = 0.3, d_h = 0.5, l_r = 0.01, la1p = 0.1, la2p = 0.1, la3p = 0.5):\n",
    "    \n",
    "    input_var = T.matrix('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    \n",
    "    print(\"Building model and compiling functions...\")\n",
    "    \n",
    "    layer_in = lasagne.layers.InputLayer(shape=(None, 90), input_var=input_var)\n",
    "    if d_i:\n",
    "        layer_in = lasagne.layers.dropout(layer_in, p=d_i)\n",
    "    \n",
    "    # Hidden layers and dropout:\n",
    "    \n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    layer1 = lasagne.layers.DenseLayer(layer_in, width, nonlinearity=nonlin)\n",
    "    if d_h:\n",
    "        layer1 = lasagne.layers.dropout(layer1, p=d_h)\n",
    "        \n",
    "    #layer2 = lasagne.layers.DenseLayer(layer1, width, nonlinearity=nonlin)\n",
    "    #if d_h:\n",
    "    #    layer2 = lasagne.layers.dropout(layer2, p=d_h)\n",
    "        \n",
    "    #layer3 = lasagne.layers.DenseLayer(layer2, width, nonlinearity=nonlin)\n",
    "    #if d_h:\n",
    "    #    layer3 = lasagne.layers.dropout(layer3, p=d_h)\n",
    "        \n",
    "    #layer4 = lasagne.layers.DenseLayer(layer3, width, nonlinearity=nonlin)\n",
    "    #if d_h:\n",
    "    #    layer4 = lasagne.layers.dropout(layer4, p=d_h)\n",
    "        \n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(layer1, 5, nonlinearity=softmax)\n",
    "    \n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    #layers = {layer1: la1p, layer2: la2p, network: la3p}\n",
    "    #l2_penalty_1 = lasagne.regularization.regularize_layer_params_weighted({layer1:la1p}, lasagne.regularization.l2)\n",
    "    #l2_penalty = lasagne.regularization.regularize_layer_params(network, lasagne.regularization.l2)*1e-03\n",
    "    #loss = loss.mean() + l2_penalty + l1_penalty\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=l_r, momentum=0.7)\n",
    "    \n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "    #test_loss = test_loss.mean() + l2_penalty + l1_penalty\n",
    "    test_loss = test_loss.mean()\n",
    "    \n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    \n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    global percs\n",
    "    percs = array([])\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        perc = val_acc / val_batches\n",
    "        percs = append(percs, perc)\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(perc * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, zeros(len(X_test)), 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "    print(\"Percentages average:\\t\\t\\t{:.5f}\".format(mean(percs)))\n",
    "    print(\"\\a\")\n",
    "    global result\n",
    "    result = lasagne.layers.get_output(network, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 0.757s\n",
      "  training loss:\t\t0.815702\n",
      "  validation loss:\t\t0.557968\n",
      "  validation accuracy:\t\t81.04 %\n",
      "Epoch 2 of 500 took 0.729s\n",
      "  training loss:\t\t0.535791\n",
      "  validation loss:\t\t0.455412\n",
      "  validation accuracy:\t\t84.72 %\n",
      "Epoch 3 of 500 took 0.739s\n",
      "  training loss:\t\t0.456738\n",
      "  validation loss:\t\t0.398103\n",
      "  validation accuracy:\t\t87.00 %\n",
      "Epoch 4 of 500 took 0.776s\n",
      "  training loss:\t\t0.408175\n",
      "  validation loss:\t\t0.362540\n",
      "  validation accuracy:\t\t88.16 %\n",
      "Epoch 5 of 500 took 0.739s\n",
      "  training loss:\t\t0.375636\n",
      "  validation loss:\t\t0.333460\n",
      "  validation accuracy:\t\t89.14 %\n",
      "Epoch 6 of 500 took 0.745s\n",
      "  training loss:\t\t0.351001\n",
      "  validation loss:\t\t0.318163\n",
      "  validation accuracy:\t\t89.54 %\n",
      "Epoch 7 of 500 took 0.735s\n",
      "  training loss:\t\t0.333355\n",
      "  validation loss:\t\t0.300175\n",
      "  validation accuracy:\t\t90.18 %\n",
      "Epoch 8 of 500 took 0.791s\n",
      "  training loss:\t\t0.317092\n",
      "  validation loss:\t\t0.286455\n",
      "  validation accuracy:\t\t90.92 %\n",
      "Epoch 9 of 500 took 0.730s\n",
      "  training loss:\t\t0.304449\n",
      "  validation loss:\t\t0.275668\n",
      "  validation accuracy:\t\t91.16 %\n",
      "Epoch 10 of 500 took 0.720s\n",
      "  training loss:\t\t0.295597\n",
      "  validation loss:\t\t0.265007\n",
      "  validation accuracy:\t\t91.46 %\n",
      "Epoch 11 of 500 took 0.741s\n",
      "  training loss:\t\t0.284355\n",
      "  validation loss:\t\t0.256470\n",
      "  validation accuracy:\t\t91.76 %\n",
      "Epoch 12 of 500 took 0.718s\n",
      "  training loss:\t\t0.276478\n",
      "  validation loss:\t\t0.251254\n",
      "  validation accuracy:\t\t91.88 %\n",
      "Epoch 13 of 500 took 0.717s\n",
      "  training loss:\t\t0.270181\n",
      "  validation loss:\t\t0.244113\n",
      "  validation accuracy:\t\t92.32 %\n",
      "Epoch 14 of 500 took 0.724s\n",
      "  training loss:\t\t0.264575\n",
      "  validation loss:\t\t0.240547\n",
      "  validation accuracy:\t\t92.42 %\n",
      "Epoch 15 of 500 took 0.718s\n",
      "  training loss:\t\t0.257365\n",
      "  validation loss:\t\t0.233597\n",
      "  validation accuracy:\t\t92.60 %\n",
      "Epoch 16 of 500 took 0.717s\n",
      "  training loss:\t\t0.249739\n",
      "  validation loss:\t\t0.229226\n",
      "  validation accuracy:\t\t92.70 %\n",
      "Epoch 17 of 500 took 0.721s\n",
      "  training loss:\t\t0.245815\n",
      "  validation loss:\t\t0.225192\n",
      "  validation accuracy:\t\t92.82 %\n",
      "Epoch 18 of 500 took 0.723s\n",
      "  training loss:\t\t0.240666\n",
      "  validation loss:\t\t0.221111\n",
      "  validation accuracy:\t\t92.86 %\n",
      "Epoch 19 of 500 took 0.717s\n",
      "  training loss:\t\t0.236076\n",
      "  validation loss:\t\t0.216499\n",
      "  validation accuracy:\t\t93.08 %\n",
      "Epoch 20 of 500 took 0.719s\n",
      "  training loss:\t\t0.231897\n",
      "  validation loss:\t\t0.214163\n",
      "  validation accuracy:\t\t93.14 %\n",
      "Epoch 21 of 500 took 0.721s\n",
      "  training loss:\t\t0.229812\n",
      "  validation loss:\t\t0.212466\n",
      "  validation accuracy:\t\t93.16 %\n",
      "Epoch 22 of 500 took 0.716s\n",
      "  training loss:\t\t0.223103\n",
      "  validation loss:\t\t0.208907\n",
      "  validation accuracy:\t\t93.22 %\n",
      "Epoch 23 of 500 took 0.719s\n",
      "  training loss:\t\t0.220587\n",
      "  validation loss:\t\t0.205429\n",
      "  validation accuracy:\t\t93.26 %\n",
      "Epoch 24 of 500 took 0.726s\n",
      "  training loss:\t\t0.218345\n",
      "  validation loss:\t\t0.203241\n",
      "  validation accuracy:\t\t93.46 %\n",
      "Epoch 25 of 500 took 0.719s\n",
      "  training loss:\t\t0.216308\n",
      "  validation loss:\t\t0.201071\n",
      "  validation accuracy:\t\t93.52 %\n",
      "Epoch 26 of 500 took 0.722s\n",
      "  training loss:\t\t0.211702\n",
      "  validation loss:\t\t0.198386\n",
      "  validation accuracy:\t\t93.52 %\n",
      "Epoch 27 of 500 took 0.721s\n",
      "  training loss:\t\t0.209283\n",
      "  validation loss:\t\t0.196325\n",
      "  validation accuracy:\t\t93.54 %\n",
      "Epoch 28 of 500 took 0.720s\n",
      "  training loss:\t\t0.206380\n",
      "  validation loss:\t\t0.193832\n",
      "  validation accuracy:\t\t93.72 %\n",
      "Epoch 29 of 500 took 0.722s\n",
      "  training loss:\t\t0.203053\n",
      "  validation loss:\t\t0.192432\n",
      "  validation accuracy:\t\t93.66 %\n",
      "Epoch 30 of 500 took 0.725s\n",
      "  training loss:\t\t0.202556\n",
      "  validation loss:\t\t0.190366\n",
      "  validation accuracy:\t\t93.68 %\n",
      "Epoch 31 of 500 took 0.720s\n",
      "  training loss:\t\t0.200073\n",
      "  validation loss:\t\t0.189874\n",
      "  validation accuracy:\t\t93.98 %\n",
      "Epoch 32 of 500 took 0.727s\n",
      "  training loss:\t\t0.196719\n",
      "  validation loss:\t\t0.187055\n",
      "  validation accuracy:\t\t93.94 %\n",
      "Epoch 33 of 500 took 0.725s\n",
      "  training loss:\t\t0.196191\n",
      "  validation loss:\t\t0.185709\n",
      "  validation accuracy:\t\t94.08 %\n",
      "Epoch 34 of 500 took 0.720s\n",
      "  training loss:\t\t0.193972\n",
      "  validation loss:\t\t0.183361\n",
      "  validation accuracy:\t\t94.02 %\n",
      "Epoch 35 of 500 took 0.725s\n",
      "  training loss:\t\t0.192766\n",
      "  validation loss:\t\t0.182692\n",
      "  validation accuracy:\t\t94.08 %\n",
      "Epoch 36 of 500 took 0.727s\n",
      "  training loss:\t\t0.189004\n",
      "  validation loss:\t\t0.180720\n",
      "  validation accuracy:\t\t94.06 %\n",
      "Epoch 37 of 500 took 0.727s\n",
      "  training loss:\t\t0.185402\n",
      "  validation loss:\t\t0.179447\n",
      "  validation accuracy:\t\t94.16 %\n",
      "Epoch 38 of 500 took 0.728s\n",
      "  training loss:\t\t0.185069\n",
      "  validation loss:\t\t0.178699\n",
      "  validation accuracy:\t\t94.24 %\n",
      "Epoch 39 of 500 took 0.721s\n",
      "  training loss:\t\t0.187262\n",
      "  validation loss:\t\t0.176036\n",
      "  validation accuracy:\t\t94.36 %\n",
      "Epoch 40 of 500 took 0.725s\n",
      "  training loss:\t\t0.181757\n",
      "  validation loss:\t\t0.176094\n",
      "  validation accuracy:\t\t94.36 %\n",
      "Epoch 41 of 500 took 0.727s\n",
      "  training loss:\t\t0.180927\n",
      "  validation loss:\t\t0.174010\n",
      "  validation accuracy:\t\t94.48 %\n",
      "Epoch 42 of 500 took 0.725s\n",
      "  training loss:\t\t0.180408\n",
      "  validation loss:\t\t0.174640\n",
      "  validation accuracy:\t\t94.36 %\n",
      "Epoch 43 of 500 took 0.725s\n",
      "  training loss:\t\t0.177661\n",
      "  validation loss:\t\t0.171783\n",
      "  validation accuracy:\t\t94.50 %\n",
      "Epoch 44 of 500 took 0.723s\n",
      "  training loss:\t\t0.176868\n",
      "  validation loss:\t\t0.170793\n",
      "  validation accuracy:\t\t94.58 %\n",
      "Epoch 45 of 500 took 0.727s\n",
      "  training loss:\t\t0.176787\n",
      "  validation loss:\t\t0.170964\n",
      "  validation accuracy:\t\t94.64 %\n",
      "Epoch 46 of 500 took 0.732s\n",
      "  training loss:\t\t0.174678\n",
      "  validation loss:\t\t0.169240\n",
      "  validation accuracy:\t\t94.52 %\n",
      "Epoch 47 of 500 took 0.723s\n",
      "  training loss:\t\t0.173184\n",
      "  validation loss:\t\t0.168162\n",
      "  validation accuracy:\t\t94.66 %\n",
      "Epoch 48 of 500 took 0.728s\n",
      "  training loss:\t\t0.172336\n",
      "  validation loss:\t\t0.167705\n",
      "  validation accuracy:\t\t94.64 %\n",
      "Epoch 49 of 500 took 0.726s\n",
      "  training loss:\t\t0.170745\n",
      "  validation loss:\t\t0.166440\n",
      "  validation accuracy:\t\t94.60 %\n",
      "Epoch 50 of 500 took 0.725s\n",
      "  training loss:\t\t0.166542\n",
      "  validation loss:\t\t0.165446\n",
      "  validation accuracy:\t\t94.68 %\n",
      "Epoch 51 of 500 took 0.723s\n",
      "  training loss:\t\t0.167411\n",
      "  validation loss:\t\t0.164407\n",
      "  validation accuracy:\t\t94.68 %\n",
      "Epoch 52 of 500 took 0.730s\n",
      "  training loss:\t\t0.163634\n",
      "  validation loss:\t\t0.164718\n",
      "  validation accuracy:\t\t94.60 %\n",
      "Epoch 53 of 500 took 0.739s\n",
      "  training loss:\t\t0.163451\n",
      "  validation loss:\t\t0.162992\n",
      "  validation accuracy:\t\t94.66 %\n",
      "Epoch 54 of 500 took 0.727s\n",
      "  training loss:\t\t0.163675\n",
      "  validation loss:\t\t0.162573\n",
      "  validation accuracy:\t\t94.86 %\n",
      "Epoch 55 of 500 took 0.725s\n",
      "  training loss:\t\t0.164623\n",
      "  validation loss:\t\t0.161794\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 56 of 500 took 0.724s\n",
      "  training loss:\t\t0.161287\n",
      "  validation loss:\t\t0.160384\n",
      "  validation accuracy:\t\t94.92 %\n",
      "Epoch 57 of 500 took 0.725s\n",
      "  training loss:\t\t0.160094\n",
      "  validation loss:\t\t0.162223\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 58 of 500 took 0.728s\n",
      "  training loss:\t\t0.158704\n",
      "  validation loss:\t\t0.160204\n",
      "  validation accuracy:\t\t94.86 %\n",
      "Epoch 59 of 500 took 0.730s\n",
      "  training loss:\t\t0.158222\n",
      "  validation loss:\t\t0.159456\n",
      "  validation accuracy:\t\t94.88 %\n",
      "Epoch 60 of 500 took 0.727s\n",
      "  training loss:\t\t0.160241\n",
      "  validation loss:\t\t0.158319\n",
      "  validation accuracy:\t\t94.84 %\n",
      "Epoch 61 of 500 took 0.728s\n",
      "  training loss:\t\t0.156749\n",
      "  validation loss:\t\t0.157673\n",
      "  validation accuracy:\t\t94.98 %\n",
      "Epoch 62 of 500 took 0.724s\n",
      "  training loss:\t\t0.156262\n",
      "  validation loss:\t\t0.158014\n",
      "  validation accuracy:\t\t94.98 %\n",
      "Epoch 63 of 500 took 0.725s\n",
      "  training loss:\t\t0.154836\n",
      "  validation loss:\t\t0.156152\n",
      "  validation accuracy:\t\t95.00 %\n",
      "Epoch 64 of 500 took 0.726s\n",
      "  training loss:\t\t0.154280\n",
      "  validation loss:\t\t0.157360\n",
      "  validation accuracy:\t\t94.96 %\n",
      "Epoch 65 of 500 took 0.726s\n",
      "  training loss:\t\t0.153143\n",
      "  validation loss:\t\t0.156221\n",
      "  validation accuracy:\t\t95.04 %\n",
      "Epoch 66 of 500 took 0.730s\n",
      "  training loss:\t\t0.151267\n",
      "  validation loss:\t\t0.155423\n",
      "  validation accuracy:\t\t94.96 %\n",
      "Epoch 67 of 500 took 0.725s\n",
      "  training loss:\t\t0.153208\n",
      "  validation loss:\t\t0.155512\n",
      "  validation accuracy:\t\t95.14 %\n",
      "Epoch 68 of 500 took 0.734s\n",
      "  training loss:\t\t0.150088\n",
      "  validation loss:\t\t0.153736\n",
      "  validation accuracy:\t\t95.12 %\n",
      "Epoch 69 of 500 took 0.735s\n",
      "  training loss:\t\t0.150105\n",
      "  validation loss:\t\t0.153973\n",
      "  validation accuracy:\t\t95.08 %\n",
      "Epoch 70 of 500 took 0.727s\n",
      "  training loss:\t\t0.149601\n",
      "  validation loss:\t\t0.153825\n",
      "  validation accuracy:\t\t95.12 %\n",
      "Epoch 71 of 500 took 0.724s\n",
      "  training loss:\t\t0.146007\n",
      "  validation loss:\t\t0.153154\n",
      "  validation accuracy:\t\t95.08 %\n",
      "Epoch 72 of 500 took 0.727s\n",
      "  training loss:\t\t0.147138\n",
      "  validation loss:\t\t0.151975\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 73 of 500 took 0.734s\n",
      "  training loss:\t\t0.147029\n",
      "  validation loss:\t\t0.151285\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 74 of 500 took 0.726s\n",
      "  training loss:\t\t0.144055\n",
      "  validation loss:\t\t0.151885\n",
      "  validation accuracy:\t\t95.30 %\n",
      "Epoch 75 of 500 took 0.728s\n",
      "  training loss:\t\t0.147318\n",
      "  validation loss:\t\t0.151361\n",
      "  validation accuracy:\t\t95.08 %\n",
      "Epoch 76 of 500 took 0.728s\n",
      "  training loss:\t\t0.142299\n",
      "  validation loss:\t\t0.150478\n",
      "  validation accuracy:\t\t95.20 %\n",
      "Epoch 77 of 500 took 0.726s\n",
      "  training loss:\t\t0.143575\n",
      "  validation loss:\t\t0.150999\n",
      "  validation accuracy:\t\t95.26 %\n",
      "Epoch 78 of 500 took 0.727s\n",
      "  training loss:\t\t0.142128\n",
      "  validation loss:\t\t0.149985\n",
      "  validation accuracy:\t\t95.28 %\n",
      "Epoch 79 of 500 took 0.730s\n",
      "  training loss:\t\t0.139712\n",
      "  validation loss:\t\t0.148542\n",
      "  validation accuracy:\t\t95.24 %\n",
      "Epoch 80 of 500 took 0.725s\n",
      "  training loss:\t\t0.141487\n",
      "  validation loss:\t\t0.148683\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 81 of 500 took 0.725s\n",
      "  training loss:\t\t0.143453\n",
      "  validation loss:\t\t0.149107\n",
      "  validation accuracy:\t\t95.26 %\n",
      "Epoch 82 of 500 took 0.727s\n",
      "  training loss:\t\t0.139645\n",
      "  validation loss:\t\t0.148969\n",
      "  validation accuracy:\t\t95.24 %\n",
      "Epoch 83 of 500 took 0.726s\n",
      "  training loss:\t\t0.138564\n",
      "  validation loss:\t\t0.148102\n",
      "  validation accuracy:\t\t95.36 %\n",
      "Epoch 84 of 500 took 0.728s\n",
      "  training loss:\t\t0.140217\n",
      "  validation loss:\t\t0.146840\n",
      "  validation accuracy:\t\t95.30 %\n",
      "Epoch 85 of 500 took 0.729s\n",
      "  training loss:\t\t0.138570\n",
      "  validation loss:\t\t0.146964\n",
      "  validation accuracy:\t\t95.30 %\n",
      "Epoch 86 of 500 took 0.786s\n",
      "  training loss:\t\t0.137668\n",
      "  validation loss:\t\t0.147716\n",
      "  validation accuracy:\t\t95.32 %\n",
      "Epoch 87 of 500 took 0.755s\n",
      "  training loss:\t\t0.135918\n",
      "  validation loss:\t\t0.146094\n",
      "  validation accuracy:\t\t95.36 %\n",
      "Epoch 88 of 500 took 0.791s\n",
      "  training loss:\t\t0.136442\n",
      "  validation loss:\t\t0.146439\n",
      "  validation accuracy:\t\t95.52 %\n",
      "Epoch 89 of 500 took 0.933s\n",
      "  training loss:\t\t0.137643\n",
      "  validation loss:\t\t0.147613\n",
      "  validation accuracy:\t\t95.44 %\n",
      "Epoch 90 of 500 took 0.781s\n",
      "  training loss:\t\t0.134586\n",
      "  validation loss:\t\t0.146797\n",
      "  validation accuracy:\t\t95.38 %\n",
      "Epoch 91 of 500 took 0.780s\n",
      "  training loss:\t\t0.134907\n",
      "  validation loss:\t\t0.146223\n",
      "  validation accuracy:\t\t95.36 %\n",
      "Epoch 92 of 500 took 0.782s\n",
      "  training loss:\t\t0.133394\n",
      "  validation loss:\t\t0.145629\n",
      "  validation accuracy:\t\t95.54 %\n",
      "Epoch 93 of 500 took 0.835s\n",
      "  training loss:\t\t0.132704\n",
      "  validation loss:\t\t0.145740\n",
      "  validation accuracy:\t\t95.52 %\n",
      "Epoch 94 of 500 took 0.758s\n",
      "  training loss:\t\t0.134438\n",
      "  validation loss:\t\t0.144438\n",
      "  validation accuracy:\t\t95.52 %\n",
      "Epoch 95 of 500 took 0.856s\n",
      "  training loss:\t\t0.132847\n",
      "  validation loss:\t\t0.146040\n",
      "  validation accuracy:\t\t95.42 %\n",
      "Epoch 96 of 500 took 0.771s\n",
      "  training loss:\t\t0.133594\n",
      "  validation loss:\t\t0.144031\n",
      "  validation accuracy:\t\t95.54 %\n",
      "Epoch 97 of 500 took 0.790s\n",
      "  training loss:\t\t0.133930\n",
      "  validation loss:\t\t0.144331\n",
      "  validation accuracy:\t\t95.56 %\n",
      "Epoch 98 of 500 took 0.802s\n",
      "  training loss:\t\t0.131611\n",
      "  validation loss:\t\t0.144838\n",
      "  validation accuracy:\t\t95.58 %\n",
      "Epoch 99 of 500 took 0.809s\n",
      "  training loss:\t\t0.129942\n",
      "  validation loss:\t\t0.143263\n",
      "  validation accuracy:\t\t95.54 %\n",
      "Epoch 100 of 500 took 0.891s\n",
      "  training loss:\t\t0.130852\n",
      "  validation loss:\t\t0.143853\n",
      "  validation accuracy:\t\t95.58 %\n",
      "Epoch 101 of 500 took 0.859s\n",
      "  training loss:\t\t0.131520\n",
      "  validation loss:\t\t0.144784\n",
      "  validation accuracy:\t\t95.60 %\n",
      "Epoch 102 of 500 took 0.791s\n",
      "  training loss:\t\t0.130335\n",
      "  validation loss:\t\t0.143207\n",
      "  validation accuracy:\t\t95.50 %\n",
      "Epoch 103 of 500 took 0.722s\n",
      "  training loss:\t\t0.128759\n",
      "  validation loss:\t\t0.142612\n",
      "  validation accuracy:\t\t95.62 %\n",
      "Epoch 104 of 500 took 0.715s\n",
      "  training loss:\t\t0.128236\n",
      "  validation loss:\t\t0.143699\n",
      "  validation accuracy:\t\t95.54 %\n",
      "Epoch 105 of 500 took 0.777s\n",
      "  training loss:\t\t0.129262\n",
      "  validation loss:\t\t0.142572\n",
      "  validation accuracy:\t\t95.56 %\n",
      "Epoch 106 of 500 took 0.746s\n",
      "  training loss:\t\t0.127426\n",
      "  validation loss:\t\t0.142334\n",
      "  validation accuracy:\t\t95.54 %\n",
      "Epoch 107 of 500 took 0.793s\n",
      "  training loss:\t\t0.126730\n",
      "  validation loss:\t\t0.142643\n",
      "  validation accuracy:\t\t95.66 %\n",
      "Epoch 108 of 500 took 0.784s"
     ]
    }
   ],
   "source": [
    "train_NN(num_epochs=500, width = 250, d_i = 0.0, d_h = 0.3, l_r = 0.1, la1p = 0.5, la2p = 0.5, la3p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x109406dd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK8JJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1093cd0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(arange(len(percs)),percs)\n",
    "#axis([70,100,0.95,0.97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.45289123e-04,   4.16282240e-06,   1.55890373e-03,\n",
       "          1.51584612e-02,   9.82333183e-01],\n",
       "       [  6.41078544e-05,   1.15944147e-05,   3.94361101e-03,\n",
       "          9.92972350e-01,   3.00833635e-03],\n",
       "       [  2.29302282e-06,   2.05890034e-07,   1.34860434e-08,\n",
       "          9.98882537e-01,   1.11495060e-03],\n",
       "       ..., \n",
       "       [  9.99998941e-01,   1.02575717e-06,   9.48466298e-09,\n",
       "          2.33652377e-08,   8.40457360e-11],\n",
       "       [  9.99265273e-01,   1.65950219e-12,   2.97441426e-07,\n",
       "          3.88295303e-04,   3.46134035e-04],\n",
       "       [  1.43828707e-04,   9.86642872e-08,   9.77322786e-01,\n",
       "          9.54002204e-04,   2.15792843e-02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = result.eval()\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2735 index: 6090\n"
     ]
    }
   ],
   "source": [
    "y_output = list([])\n",
    "p_output = list([])\n",
    "for i in arange(len(final)):\n",
    "    my_list = final[i,:]\n",
    "    max_index = my_list.argmax()\n",
    "    p_output.append(my_list[max_index])\n",
    "    y_output.append(max_index)\n",
    "p_output = asarray(p_output)\n",
    "mini = p_output.argmin()\n",
    "print('{:.4f} index: {:d}'.format(p_output[mini],mini)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8137"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result15.csv', 'wb') as fp:\n",
    "    a = csv.writer(fp, delimiter=',')\n",
    "    a.writerow(('Id','y'))\n",
    "    a.writerows(zip(ids,y_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
